<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Meta tags and SEO -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Yunzhen Feng">
    <meta name="description" content="Yunzhen Feng's personal website">
    <meta name="keywords" content="machine learning, deep learning, research, PhD">
    
    <title>Yunzhen Feng</title>
    
    <!-- Fonts and Icons -->
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <!-- Custom CSS -->
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <main class="wrapper">
        <div class="content">
            <section class="container">
                <!-- Profile Section -->
                <section class="container centered">
                    <div class="about">
                        <div class="avatar">
                            <img src="figures/2_1.jpg" alt="avatar">
                        </div>
                        
                        <h1>Yunzhen Feng</h1>
                        <h2>Machine Learning Researcher</h2>
                        
                        <!-- Social Media Icons -->
                        <ul class="social-icons">
                            <li>
                                <a href="https://github.com/fengyzpku" aria-label="Github">
                                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/yunzhen-feng-5152141b4/" aria-label="linkedin">
                                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://x.com/feeelix_feng" aria-label="twitter">
                                    <i class="fab fa-twitter fa-2x" aria-hidden="true"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://scholar.google.com/citations?user=QebzOsIAAAAJ&hl" aria-label="google_scholar">
                                    <i class="ai ai-google-scholar ai-2x" aria-hidden="true"></i>
                                </a>
                            </li>
                            <li>
                                <a href="mailto:yf2231@nyu.edu" aria-label="email">
                                    <i class="fa fa-envelope fa-2x" aria-hidden="true"></i>
                                </a>
                            </li>
                        </ul>
                    </div>
                </section>

                <!-- Main Content -->
                <section class="container text-justify">

                    <!-- About Section -->
                    <div class="about-text">
                        <p>I'm a final year PhD candidate at Center for Data Science, New York University, under the supervision of Prof. 
                            <a href="https://cims.nyu.edu/~kempe/">Julia Kempe</a>. My research spans synthetic data, reinforcement learning, and LLM reasoning, with a current focus on the reliability and memory mechanisms of LLM agents.
                        </p>

                        <p>At NYU, I have had the privilege of collaborating with Prof. <a href="https://hhexiy.github.io/">He He</a>, Prof. <a href="https://timrudner.com/">Tim G. J. Rudner</a>, Prof. <a href="https://cecilialeiqi.github.io/">Qi Lei</a>, and Prof. <a href="https://duanyq22.github.io/">Yaqi Duan</a>. My industry experience includes internships at Meta, where I worked with the Meta Superintelligence Labs (MSL) team in 2025 alongside <a href="https://anthonyhartshorn.com/">Anthony Hartshorn</a>, <a href="https://cheng-zhang.org/">Cheng Zhang</a>, and <a href="https://www.linkedin.com/in/paragjain1/">Parag Jain</a>, and with the Fundamental AI Research (FAIR) team in 2024 under the guidance of <a href="http://www.yann-ollivier.org/rech/">Yann Ollivier</a> and <a href="https://f-charton.github.io/about/">François Charton</a>. In 2022, I interned at Uber, focusing on causal machine learning for marketplace optimization with <a href="https://www.linkedin.com/in/jdowlatabadi">Jason Dowlatabadi</a>, <a href="https://www.linkedin.com/in/chen-xu-5483ab23">Chen Xu</a>, and Prof. <a href="https://web.stanford.edu/~swager/">Stefan Wager</a>, Prof. <a href="https://people.orie.cornell.edu/pfrazier/">Peter Frazier</a>.
                        </p>

                        <p>I graduated from Peking University with a bachelor's in Applied Mathematics (Honor Track). Back then, I was advised by Prof. <a href="http://faculty.bicmr.pku.edu.cn/~dongbin/">Bin Dong</a> , Prof. <a href="https://dihe-pku.github.io/">Di He</a>, and was fortunate to work with Prof. <a href="https://lu.seas.harvard.edu/">Yue M. Lu</a> from Harvard.
                        </p>

                        
                        <p>Feel free to <a href="mailto:yf2231@nyu.edu">contact me</a> for research collaborations or other engagements. <span style="color:#d00; font-weight:600;">I am actively looking for full-time positions in industry for 2026.</span></p>
                    </div>

                    <!-- Publications Section -->
                    <h3>Selected Publications</h3>

                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="" alt="Paper Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Internship Projects under Review</u></strong></span><br/>
                                <!-- <span>Pu Yang*, <strong>Yunzhen Feng</strong>*, Ziyuan Chen*, Yuhang Wu, Zhuoyuan Li.</span><br/>
                                <span><i>Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025, <span style="color:#d00; font-weight:600;">Spotlight</span>.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2501.18962">Paper</a>]</span><br/> -->
                            </p>
                        </div>
                    </div>
                    
                    <!-- Publication 1 -->
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/spend_wisely.png" alt="Paper 2 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data Boostrapping</u></strong></span><br/>
                                <span>Pu Yang*, <strong>Yunzhen Feng</strong>*, Ziyuan Chen*, Yuhang Wu, Zhuoyuan Li.</span><br/>
                                <span><i>Thirty-ninth Annual Conference on Neural Information Processing Systems (NeurIPS)</i>, 2025, <span style="color:#d00; font-weight:600;">Spotlight</span>.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2501.18962">Paper</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/pilaf.png" alt="Paper 1 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>PILAF: Optimal Human Preference Sampling for Reward Modeling.</u></strong></span><br/>
                                <span><strong>Yunzhen Feng</strong>, Ariel Kwiatkowski, Kunhao Zheng, Julia Kempe, Yaqi Duan.</span><br/>
                                <span><i>International Conference on Machine Learning (ICML)</i>, 2025.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2502.04270">Paper</a>]</span><br/>
                                <!-- [<a href="#">Code</a>] [<a href="#">Project Page</a>] -->
                            </p>
                        </div>
                    </div>
                    
                    <!-- Publication 2 -->
                    
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/strong_model_collapse.png" alt="Paper 2 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Strong Model Collapse.</u></strong></span><br/>
                                <span>Elvis Dohmatob, <strong>Yunzhen Feng</strong>, Arjun Subramonian, Julia Kempe.</span><br/>
                                <span><i>International Conference on Learning Representations (ICLR)</i>, 2025, <span style="color:#d00; font-weight:600;">Spotlight</span>.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2410.04840">Paper</a>]</span><br/>
                                <span>Covered Media: [新智元] [机器之心] [<a href="https://www.deutschlandfunk.de/ki-kollaps-daten-sprachmodelle-training-dlf-d0b03f04-100.html">German Radio Deutschlandfunk Series</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/beyond_model_collapse.png" alt="Paper 2 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Beyond Model Collapse: Scaling Up with Synthesized Data Requires Verification.</u></strong></span><br/>
                                <span><strong>Yunzhen Feng</strong>*, Elvis Dohmatob*, Pu Yang*, François Charton, Julia Kempe.</span><br/>
                                <span><i>International Conference on Learning Representations (ICLR)</i>, 2025.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2406.07515">Paper</a>]</span><br/>
                                <span>Covered Media: [<a href="https://www.nature.com/articles/d41586-024-02420-7">Nature News</a>] [<a href="https://cacm.acm.org/news/the-collapse-of-gpt/">Communications of the ACM</a>] [<a href="https://www.transformernews.ai/p/synthetic-data-model-collapse-fears">Transformer Ai.</a>] [<a href="https://nyudatascience.medium.com/overcoming-the-ai-data-crisis-a-new-solution-to-model-collapse-ddc5b382e182">The NYU Data Science News</a>] [<a href="https://www.marktechpost.com/2024/06/15/scaling-ai-models-combating-collapse-with-reinforced-synthetic-data/"> MarkTechPost</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <!-- Publication 5 -->
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/tale_of_tail.png" alt="Paper 5 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>A Tale of Tails: Model Collapse as a Change of Scaling Laws</u></strong></span><br/>
                                <span><strong>Yunzhen Feng</strong>*, Elvis Dohmatob*, Pu Yang, François Charton, Julia Kempe.</span><br/>
                                <span><i>International Conference on Machine Learning (ICML)</i>, 2024.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2402.07043">Paper</a>]</span><br/>
                                <span>Covered Media: [<a href="https://www.nytimes.com/interactive/2024/08/26/upshot/ai-synthetic-data.html">New York Times</a>] [<a href="https://www.lesechos.fr/idees-debats/sciences-prospective/intelligence-artificielle-la-guerre-des-donnees-2103624">Les Echos</a>] [<a href="https://www.theregister.com/2024/05/09/ai_model_collapse/">The Register</a>] [<a href="https://www.theglobeandmail.com/business/article-training-ai-models-generated-data-llms/">The Globe and Mail</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <!-- Publication 6 -->
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/efficient_transformers.png" alt="Paper 6 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Do Efficient Transformers Really Save Computation?</u></strong></span><br/>
                                <span>Kai Yang, Jan Ackermann, Zhenyu He, Guhao Feng, Bohang Zhang, <strong>Yunzhen Feng</strong>, Qiwei Ye, Di He, Liwei Wang.</span><br/>
                                <span><i>International Conference on Machine Learning (ICML)</i>, 2024.</span><br/>
                                <span>[<a href="https://arxiv.org/abs/2402.13934">Paper</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <!-- Publication 7 -->
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/dataset_distillation.png" alt="Paper 7 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Embarrassingly Simple Dataset Distillation</u></strong></span><br/>
                                <span><strong>Yunzhen Feng</strong>, Ramakrishna Vedantam, Julia Kempe.</span><br/>
                                <span><i>International Conference on Learning Representations (ICLR)</i>, 2024.</span><br/>
                                <span>[<a href="https://openreview.net/forum?id=PLoWVP7Mjc">Paper</a>] [<a href="https://github.com/fengyzpku/Simple_Dataset_Distillation">Code</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <!-- Publication 8 -->
                    <div class="publication-item">
                        <div class="pub-figure">
                            <img src="figures/papers/bayes.png" alt="Paper 8 Figure" class="pub-image">
                        </div>
                        <div class="pub-content">
                            <p>
                                <span><strong><u>Attacking Bayes: Are Bayesian Neural Networks Inherently Robust?</u></strong></span><br/>
                                <span><strong>Yunzhen Feng</strong>, Nikos Tsilivis, Tim G. J. Rudner, Julia Kempe.</span><br/>
                                <span><i>Transactions on Machine Learning Research (TMLR)</i>, 2024, <span style="color:#d00; font-weight:600;">Reproducibility Certification</span>.</span><br/>
                                <span>[<a href="https://openreview.net/forum?id=dYeYo32sXLz">Paper</a>] [<a href="https://github.com/fengyzpku/attacking-bayes">Code</a>]</span><br/>
                            </p>
                        </div>
                    </div>

                    <!-- Education Section -->
                    <h3>Education</h3>
                    <p>
                        <span><strong>New York University</strong>, New York, NY. Candidate for Doctor of Philosophy in Data Science. Sep. 2021 – Summer 2026 (projected).</span><br/><br/>
                        <span><strong>Peking University</strong>, Beijing, China. Bachelor of Science in Applied Mathematics (Honor Track). Sep. 2017 – Jul. 2021.</span><br/><br/>
                    </p>

                    <!-- Honors & Awards Section -->
                    <h3>Miscellaneous</h3>
                    <p>
                        <span>I am an outdoor lover. I climbed the Luodui Mount (6010m Snowberg) at Tibet, China in August, 2021. I have also served as the teaching assistant of *Outdoor Exploration* at Peking University. Outdoor experiences really help shape my personality and life methodology.</span><br/>
                    </p>
                </section>
            </section>
        </div>
    </main>

    <!-- 
    MODIFICATION GUIDE:
    
    1. UPDATE SOCIAL MEDIA LINKS:
       - Replace "yourusername" with your actual usernames
       - Replace "YOUR_ID" with your Google Scholar ID
       - Replace email with your actual email
    
    2. ADD PUBLICATIONS:
       Copy this structure for each new publication:
       
       <div class="publication-item">
           <div class="pub-figure">
               <img src="figures/your-paper.png" alt="Paper Figure" class="pub-image">
           </div>
           <div class="pub-content">
               <p>
                   <span><strong><u>Paper Title</u></strong></span><br/>
                   <span><strong>Your Name</strong>, Co-authors.</span><br/>
                   <span><i>Venue</i>, Year.</span><br/>
                   <span>[<a href="#">Paper</a>] [<a href="#">Code</a>]</span><br/>
               </p>
           </div>
       </div>
    
    3. UPDATE PERSONAL INFO:
       - Change name, university, advisor
       - Update research interests
       - Modify education details
       - Add your awards and honors
    -->
</body>
</html>
